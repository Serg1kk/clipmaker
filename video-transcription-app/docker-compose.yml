# Video Transcription Pipeline - Docker Compose Configuration
# Optimized for Apple Silicon M1/M2 (ARM64) with 16GB RAM
#
# Architecture:
#   - whisper: FFmpeg + whisper.cpp for transcription (ARM64 optimized)
#   - backend: FastAPI Python service for API and processing
#   - frontend: Vite React app served via nginx
#
# Usage:
#   docker-compose up -d
#   docker-compose logs -f
#   docker-compose down

version: '3.9'

# ============================================================================
# NETWORKS
# ============================================================================
networks:
  transcription-net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

# ============================================================================
# VOLUMES
# ============================================================================
volumes:
  # Persistent whisper models (downloaded once, reused)
  whisper-models:
    driver: local

  # Shared processing directory between services
  shared-processing:
    driver: local

  # Project data persistence
  project-data:
    driver: local

# ============================================================================
# SERVICES
# ============================================================================
services:
  # --------------------------------------------------------------------------
  # WHISPER SERVICE - Transcription Engine
  # --------------------------------------------------------------------------
  # Handles: Audio extraction (FFmpeg) + Speech-to-text (whisper.cpp)
  # Optimized for M1/ARM64 with Metal acceleration
  # --------------------------------------------------------------------------
  whisper:
    build:
      context: ./whisper
      dockerfile: Dockerfile
      args:
        - WHISPER_MODEL=base  # Options: tiny, base, small, medium, large
    image: video-transcription/whisper:latest
    container_name: transcription-whisper

    # ARM64/M1 platform specification
    platform: linux/arm64

    # Resource constraints for 16GB M1
    deploy:
      resources:
        limits:
          memory: 8G      # 8GB max for whisper processing
          cpus: '6'       # 6 of 8 cores for transcription
        reservations:
          memory: 4G      # Minimum 4GB reserved
          cpus: '4'

    # Volume mappings
    volumes:
      # Whisper models - persisted between restarts
      - whisper-models:/app/models:rw

      # Shared processing directory for temp files
      - shared-processing:/app/processing:rw

      # Output directory for transcripts
      - ./output:/app/output:rw

    # Environment configuration
    environment:
      - WHISPER_MODEL_PATH=/app/models
      - WHISPER_OUTPUT_PATH=/app/output
      - WHISPER_PROCESSING_PATH=/app/processing
      - WHISPER_THREADS=6
      - WHISPER_LANGUAGE=auto  # Auto-detect language
      - FFMPEG_THREADS=4
      # Word-level timestamps for precise clip cutting
      - WHISPER_WORD_TIMESTAMPS=true
      - LOG_LEVEL=INFO

    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    # Networking
    networks:
      transcription-net:
        ipv4_address: 172.28.0.10

    # Expose internal API port
    expose:
      - "8001"

    # Restart policy
    restart: unless-stopped

    # Logging
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # --------------------------------------------------------------------------
  # BACKEND SERVICE - FastAPI Application Server
  # --------------------------------------------------------------------------
  # Handles: API endpoints, video processing orchestration, project management
  # Communicates with whisper service and external APIs (OpenRouter/Gemini)
  # --------------------------------------------------------------------------
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    image: video-transcription/backend:latest
    container_name: transcription-backend

    platform: linux/arm64

    # Resource constraints
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2'
        reservations:
          memory: 512M
          cpus: '1'

    # Volume mappings
    volumes:
      # Local video files - READ-ONLY access for security
      # User configures this path to their video library
      - ${VIDEO_SOURCE_PATH:-~/Videos}:/app/videos:ro

      # Shared processing directory
      - shared-processing:/app/processing:rw

      # Output directory for final clips
      - ./output:/app/output:rw

      # Project data persistence (history, settings)
      - project-data:/app/data:rw

      # Whisper models access (read-only for status checks)
      - whisper-models:/app/models:ro

    # Environment configuration
    environment:
      # API Configuration
      - API_HOST=0.0.0.0
      - API_PORT=8000

      # Whisper service connection
      - WHISPER_SERVICE_URL=http://whisper:8001

      # External API keys (via .env file)
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - GEMINI_MODEL=${GEMINI_MODEL:-google/gemini-2.5-pro-preview}

      # Path configurations
      - VIDEO_INPUT_PATH=/app/videos
      - PROCESSING_PATH=/app/processing
      - OUTPUT_PATH=/app/output
      - DATA_PATH=/app/data

      # Processing settings
      - MAX_CONCURRENT_JOBS=2
      - CLIP_MIN_DURATION=13
      - CLIP_MAX_DURATION=60

      # FFmpeg settings for final composition
      - FFMPEG_PRESET=medium
      - FFMPEG_CRF=23
      - OUTPUT_RESOLUTION=1080x1920  # 9:16 vertical

      # Subtitle settings defaults
      - SUBTITLE_FONT=Arial Bold
      - SUBTITLE_SIZE=48
      - SUBTITLE_COLOR=FFFFFF
      - SUBTITLE_OUTLINE_COLOR=000000

      # Logging
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1

    # Dependency - wait for whisper to be healthy
    depends_on:
      whisper:
        condition: service_healthy

    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s

    # Networking
    networks:
      transcription-net:
        ipv4_address: 172.28.0.20

    # Port mapping
    ports:
      - "8000:8000"

    restart: unless-stopped

    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"

  # --------------------------------------------------------------------------
  # FRONTEND SERVICE - React/Vite UI served via nginx
  # --------------------------------------------------------------------------
  # Handles: User interface, video preview, frame editor, clip selection
  # Static build served by nginx with API proxy to backend
  # --------------------------------------------------------------------------
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - VITE_API_URL=/api
    image: video-transcription/frontend:latest
    container_name: transcription-frontend

    platform: linux/arm64

    # Minimal resources for static serving
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 64M
          cpus: '0.1'

    # Volume for nginx config customization
    volumes:
      - ./frontend/nginx.conf:/etc/nginx/conf.d/default.conf:ro

    # Environment (build-time for Vite)
    environment:
      - NODE_ENV=production

    # Dependency
    depends_on:
      backend:
        condition: service_healthy

    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 10s

    # Networking
    networks:
      transcription-net:
        ipv4_address: 172.28.0.30

    # Port mapping - main entry point
    ports:
      - "3000:80"

    restart: unless-stopped

    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"

# ============================================================================
# ARCHITECTURE NOTES
# ============================================================================
#
# Service Communication Flow:
#   User -> Frontend (3000) -> Backend API (8000) -> Whisper Service (8001)
#                                    |
#                                    v
#                           OpenRouter/Gemini API
#
# Volume Strategy:
#   1. VIDEO_SOURCE_PATH (host) -> /app/videos (read-only)
#      - User's local video library, mounted read-only for safety
#      - Configured via environment variable
#
#   2. whisper-models (named volume)
#      - Persistent storage for downloaded whisper models
#      - Downloaded once, persists across container restarts
#      - ~1-3GB depending on model size
#
#   3. shared-processing (named volume)
#      - Temporary files during processing
#      - Audio extracts, intermediate transcripts
#      - Shared between whisper and backend services
#
#   4. ./output (bind mount)
#      - Final output clips and transcripts
#      - Accessible from host filesystem
#
#   5. project-data (named volume)
#      - User project history and settings
#      - Clip selections, template configurations
#
# M1/ARM64 Optimizations:
#   - All images built for linux/arm64 platform
#   - Whisper.cpp compiled with ARM NEON optimizations
#   - FFmpeg with VideoToolbox hardware acceleration
#   - Memory limits set for 16GB system
#   - CPU allocation balanced across services
#
# Startup Order:
#   1. whisper (60s startup for model loading)
#   2. backend (waits for whisper healthy)
#   3. frontend (waits for backend healthy)
