version: '3.8'

services:
  # Whisper.cpp transcription service (ARM64/M1 optimized)
  whisper:
    build:
      context: ./docker
      dockerfile: Dockerfile
      args:
        WHISPER_MODEL: base
    platform: linux/arm64
    container_name: whisper-transcriber
    volumes:
      # Mount local videos directory (read-only)
      - ./videos:/app/input:ro
      # Output directory for transcriptions
      - ./output:/app/output
      # Persist downloaded models
      - whisper-models:/app/models
    environment:
      - WHISPER_THREADS=4
      - WHISPER_LANGUAGE=auto
      - WHISPER_OUTPUT_FORMAT=txt
    # This service runs on-demand, not continuously
    profiles:
      - transcribe

  # FastAPI Backend
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    platform: linux/arm64
    container_name: transcription-backend
    ports:
      - "8000:8000"
    volumes:
      # Shared volume for video files
      - ./videos:/app/videos:ro
      # Output directory
      - ./output:/app/output
      # Uploads from frontend
      - backend-uploads:/app/uploads
    environment:
      - WHISPER_SERVICE_URL=http://whisper:5000
      - PYTHONUNBUFFERED=1
    depends_on: []
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped

  # React Frontend (Vite build served by nginx)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    platform: linux/arm64
    container_name: transcription-frontend
    ports:
      - "3000:80"
    depends_on:
      - backend
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

volumes:
  whisper-models:
    name: whisper-models-cache
  backend-uploads:
    name: transcription-uploads

networks:
  default:
    name: transcription-network
